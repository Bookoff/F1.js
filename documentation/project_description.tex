%**VARIABILI PROGETTO DA MODIFICARE****************************

\def\PROJECT		{F1.js} %Nome del documento, ad esempio: Piano di Progetto
\def\SUBTITLE		{Formula 1 in a concurrent yet distributed way}

%Personale
%se ci sono più persone da indicare scrivere: {nome1, \\&nome2, \\&nome3 ecc..}
\def\AUTHOR			{\ME}

%Variabili documento
\def\TABLES		{false} %abilita - disabilita l'indice delle tabelle
\def\FIGURES	{true} %abilita - disabilita l'indice delle figure

%importa la struttura principale
\input{template/structure}

\newpage
%************************************************
%importa i vari indici
\input{template/index}
%**********   Inizio delle "section"   ********************************

\newpage

\hspace{1cm}
\begin{center}
\section*{Abstract}
\end{center}
In this document it's described how the F1.js program has been designed and implemented. The programming language chosen for this project is node.js/Javascript, for its particular properties that makes this task a lot easier than in other languages.

With this new technology is possible to do something that requires a great amount of work in an easy way. This could be done also by the fact that in node.js there is no difference between concurrency and distribution, as it will be explained.

\newpage
\section{The language}
In order to understand how we solved the problem, is important to give an explanation of how the language, its architecture and its tools are designed. Indeed, this is not a common architecture, although there are similar examples such as Twisted for Python or Event Machine for Ruby.

\subsection{node.js features}

As said, the project has been written using node.js. Quoting the official site main page: \textit{Node.js is a platform built on Chrome's JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.}\footnote{Official node.js website: \url{http://www.nodejs.org}}

In other words, it is expressive, in particular with the Express.js framework\footnote{Official Express.js framework website: \url{http://expressjs.com/}}, fast and scalable. 

An important aspect is the use of the V8 JavaScript Engine to interpret the JavaScript code. Written by Google, it increases performance by compiling JavaScript to native machine code (x86, ARM, or MIPS CPUs)\cite{website:v8-intro}, before executing it, versus executing bytecode or interpreting it.

As you can see in Figure \ref{fig:nodeBench}, this raises a lot the performances, reaching almost Java's speed.

\begin{figure}[H]
\centering % per centrare l'immagine (opzionale)
\includegraphics[height=150px]{img/node-bench.png}
\caption{node.js benchmark versus other popular languages/platforms/frameworks}
\label{fig:nodeBench}
\end{figure}

However, the performance aren't great only for the use of V8, but also for the programming style that node.js implies.

\subsubsection{Asynchronous I/O}
\label{sec:async}

node.js real difference is the asynchronous I/O and evented support. Citing ``cloudfoundry.com'' \cite{website:cloudfoundry}: \textit{In order to write a fast and scalable server application, we typically end up writing it in a multi-threaded fashion. While you can build great multi-threaded apps in many languages, it usually requires a lot of expertise to build them correctly. On the other hand, these libraries (along with Chrome’s V8 engine) provide a different architecture that hides the complexities of multi-threaded apps while getting the same or better benefits.}

\textit{Let's compare classic multi-threaded server with an evented, non-blocking I/O server:}

\begin{figure}[H]
\centering % per centrare l'immagine (opzionale)
\includegraphics[height=150px]{img/multiThreadedServer.png}
\caption{An example multi-threaded HTTP server using blocking I/O}
\label{fig:multiThreadedServer}
\end{figure}

\textit{The diagram in Figure \ref{fig:multiThreadedServer} depicts a simplified multi-threaded server. There are four users logging into the multi-threaded server. A couple of the users are hitting refresh buttons causing it to use lot of threads. When a request comes in, one of the threads in the thread pool performs that operation, say, a blocking I/O operation. This triggers the OS to perform context switching and run other threads in the thread pool. And after some time, when the I/O is finished, the OS context switches back to the earlier thread to return the result.}

\textit{\textbf{Architecture Summary:} Multi-threaded servers supporting a synchronous, blocking I/O model provide a simpler way of performing I/O. But to handle a heavy load, multi-threaded servers end up using more threads because of the direct association to connections. Supporting more threads causes more memory and higher CPU usage due to more context switching among threads.}

\begin{figure}[H]
\centering % per centrare l'immagine (opzionale)
\includegraphics[height=150px]{img/NodeJS-EventedIOAsyncIO_latest.png}
\caption{Event-driven, non-blocking I/O (Node.js server)}
\label{fig:nodejsServer}
\end{figure}

\textit{The diagram in Figure \ref{fig:nodejsServer} depicts how Node.js server works. At a high level, Node.js server has two parts to it:}
\begin{itemize}
\item \textit{At the front, you have Chrome V8 engine (single threaded), event loop and other C/C++ libraries that run your JS code and listen to HTTP/TCP requests;}
\item \textit{And at the back of the server, you have libuv (includes libio) and other C/C++ libraries that provide asynchronous I/O.}
\end{itemize}

\textit{Whenever a request is made from a browser, mobile device, etc., the main thread running in the V8 engine checks if it is an I/O. if it is an I/O then it immediately delegates that to the backside (kernel level) of the server where one of the threads in the POSIX thread pool actually makes async I/O. Because the main thread is now free, it starts accepting new requests/events.}

\textit{And at some point when the response comes back from a database or file system, the backend piece generates an event indicating that we have a result from I/O. And when V8 becomes free from what it is currently doing (remember it is single-threaded), it takes the result and returns it to the client.}

\textit{\textbf{Architecture Summary:} This architecture utilizes an event loop (main thread) at the front and performs asynchronous I/O at the kernel level. By not directly associating connections and threads, this model needs only a main event loop thread and many fewer (kernel) threads to perform I/O. Because there are fewer threads and consequently less context-switching, it uses less memory and also less CPU.}

\subsection{Concurrency and distribution in node.js}

We have seen why an asynchronous webserver is a lot faster than a synchronous one. The fact is that performances might not be so interesting, as in this situation, but might be more interesting the easiness of designing and implementing the solution.

As said concurrency and distribution in node.js are the exact same thing. The reality indeed is that node.js is (mainly) single-threaded as seen before, handling everything with events. For this reason there isn't the concept of ``lock'' in node.js or of threads. It's possible to use webworkers that are processes that you can create forking the single-thread but are heavy and usually not needed, like in this case. They are needed only in cases of CPU-intensive tasks that might block the main thread from answering the events that it gets.

So, when you have the application that waits for an event, it's of no importance to know if the event is generated in the client, in the server or in another server. The important thing is to be subscribed to the right event emitter, and this can be easily done and changed, even at run-time.

In this way, we can run the program in a single instance on a server, in multiple processes in a single server or even split the processes in different servers without affecting the logic of the application at all. This means that we can partition vertically every single event emitter, if we want. This is a lot more scalable than rewriting the whole application or to adapt it in both cases.

\subsection{node.js versus Twisted and Event Machine}

Basically the great advantage of node.js is the use of the JavaScript language. The reason is that all the libraries already written for the JavaScript language are asynchronous, since it's how JavaScript has been designed, while Python and Ruby has a lot of synchronous libraries that you cannot use inside these two asynchronous environments.

Another important fact is that now JavaScript is an isomorphic language.\textit{By isomorphic we mean that any given line of code (with notable exceptions) can execute both on the client and the server.}\cite{website:isomorfic}

This seems trivial but it's not. Indeed we can easily communicate between client and server in a single language using events and, if needed, RPC. We can indeed write the same library for the client and the server and validate the data in each step to prevent code changes. We have no mind-switch from one language to another and the application can avoid to decouple in a strictly way view from controller from model, since the client-server limit is not so strict as in other contexts.

\subsection{socket.io, ascoltatori and redis}

\begin{figure}[H]
\centering % per centrare l'immagine (opzionale)
\includegraphics[height=250px]{img/express.png}
\caption{Express and socket.io model}
\label{fig:expressSocketio}
\end{figure}

In Figure \ref{fig:expressSocketio} you can see how the framework used and socket.io work. They are really simple and neat. Express has only the job to answer the web requests and render the HTML pages. Socket.io is a wrapper over the websocket technology.

\textbf{Socket.io} solves a lot of problems that occurs if you use the websocket technology as it is. What socket.io handles is:
\begin{itemize}
\item the connection. Websocket is a modern technology that is not allowed in old browsers. This library overcomes this problem using different technologies using the fastest available. From using Flash to return to the AJAX long-polling technology;
\item the re-connections without creating different instances but reusing the same instance that there were before the disconnection;
\item the send of JSON objects instead of plain text;
\item the namespaces. In this way you can have a single websocket connection but using different namespaces to divide different parts of the logic.
\end{itemize}

In this way, we are totally unaware of the underline problems of the network and we can handle the problem in a lot easier way.

It allows you also to pass pointers to functions that are executed in the context of definition. In this way you can simulate a Remote Procedure Call, if needed, without loosing transparency at all since it's all asynchronous. In this way, you don't need to handle problems regarding the proxy/skeleton pattern.

\textbf{Ascoltatori} is another really useful wrapper library. It is really interesting since it made a lot easier and transparent the communication server to server. Indeed it wraps a lot of ways to communicate, in particular: Redis, AMPQ (RabbitMQ), ZeroMQ, MQTT (Mosquitto) or just plain node.

In this way, we can have with no problems a node of the network written in C++ with ZeroMQ and use this library to make everything work without a change in the code.

Of the choices given, we choose \textbf{Redis} because it ``is a database, but it would be more accurately described as a datastructure server'' \cite{book:smashing}. In this way we can use only one technology. The service used is redistogo, that is an online storage service (it would work in local too, anyway).

\section{The problem}

To analyse the problem we have chosen to describe it through UML-schemas in order to have a clear path to follow. Then, each we have studied how to solve every subproblem emerged during the schema creation.

\section{Subproblems analysis}

\section{Solution: the architecture}

\section{How the solution resolves the problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%BIBLIOGRAPHY

\bibliographystyle{abbrv}
\bibliography{mybib}

\end{document}